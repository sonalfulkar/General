{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps to design & improve ML model\n",
    "\n",
    "https://developers.google.com/machine-learning/glossary\n",
    "Learn TensorFlow - https://developers.google.com/machine-learning/crash-course\n",
    "\n",
    "-pipeline\n",
    "-ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- understand the data\n",
    "\n",
    "Go through first and last few lines, use describe() and check if there are any discrepancies\n",
    "Find missing entries, see if those are really important for training.\n",
    "Map the features against target and see which ones shows major impact.\n",
    "Use heatmap to understand co-relation among the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- randomize the data before splitting, to make sure each set has variations\n",
    "- Split the data into 3 sets - train, validation, test\n",
    "splitting data into 3 sets, would help you overcome problems of overfitting. Training the data on train set\n",
    "and then constantly tweaking it on test set, makes the model overfit. It's a better practise to tweak the \n",
    "model performance on validation set and the test it on completely unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feature engineering\n",
    "It means transforming raw data into a feature vector. Expect to spend significant time doing feature engineering.\n",
    "Mapping numeric values:\n",
    "Integer and floating-point data don't need a special encoding because they can be multiplied by a numeric weight.\n",
    "Mapping categorical values:\n",
    "Categorical features have a discrete set of possible values. For example, there might be a feature called street_name with options that include: {'Charleston Road', 'North Shoreline Boulevard', 'Shorebird Way', 'Rengstorff Avenue'}\n",
    "Since models cannot multiply strings by the learned weights, we use feature engineering to convert strings to numeric values.\n",
    "\n",
    "What to use?\n",
    "One-hot encoding can be used when a single element can be mapped to 1, and a multi-hot encoding when multiple values map to 1.\n",
    "\n",
    "- Representation: Qualities of Good Features\n",
    "1. Avoid rarely used feature values\n",
    "2. Prefer meanings features\n",
    "3. Don't mix \"magic\" values with actual data\n",
    "\n",
    "For example, suppose a feature holds a floating-point value between 0 and 1. So, values like the following are fine:\n",
    "\n",
    "quality_rating: 0.82\n",
    "quality_rating: 0.37\n",
    "However, if a user didn't enter a quality_rating, perhaps the data set represented its absence with a magic value like the following:\n",
    "quality_rating: -1\n",
    "To explicitly mark magic values, create a Boolean feature that indicates whether or not a quality_rating was supplied. Give this Boolean feature a name like is_quality_rating_defined.\n",
    "\n",
    "In the original feature, replace the magic values as follows:\n",
    "\n",
    "    For variables that take a finite set of values (discrete variables), add a new value to the set and use it to signify that the feature value is missing.\n",
    "    For continuous variables, ensure missing values do not affect the model by using the mean value of the feature's data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cleaning the data\n",
    "Scaling feature values\n",
    "Scaling means converting floating-point feature values from their natural range (for example, 100 to 900) into a standard range (for example, 0 to 1 or -1 to +1)\n",
    "- Handling extreme outliers\n",
    "how? use log of every value in that feature and if it still leaves a tail on plot, cap the value.. \n",
    "something like below.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_dataframe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ef5d89d02244>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclipped_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_dataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"my_feature_name\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'my_dataframe' is not defined"
     ]
    }
   ],
   "source": [
    "clipped_feature = my_dataframe[\"my_feature_name\"].apply(lambda x: max(x, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Binning\n",
    "Add bins to understand how features can impact target\n",
    "- Data scrubbing\n",
    "Deal with cases like:\n",
    "Omitted values - For instance, a person forgot to enter a value for a house's age.\n",
    "Duplicate examples - For example, a server mistakenly uploaded the same logs twice.\n",
    "Bad labels - For instance, a person mislabeled a picture of an oak tree as a maple.\n",
    "Bad feature values - For example, someone typed in an extra digit, or a thermometer was left out in the sun.\n",
    "\n",
    "    handle them carefully, see which ones to keep and which ones to let go.\n",
    "    ALso use \n",
    "    Maximum and minimum\n",
    "    Mean and median\n",
    "    Standard deviation\n",
    "    to understand their importance\n",
    "    \n",
    "**Most important step of all is\n",
    "    Know your data -  Good ML relies on good data.\n",
    "    \n",
    "- Fix missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use of synthetic features / modified data features\n",
    "If needed combine 2 features and see if those impact the target more than individuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- choose simplest ML model if you are just starting your journey in ML\n",
    "It easier to explain and understand\n",
    "It's always a better practise to choose your ML model from at least 3 ML models; tune parameters and pick the best one\n",
    "suits your needs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check the loss\n",
    "Use confusion matrix\n",
    "Check True Positive rates and True Negative rates - See which one is more important for your business.\n",
    "Use Area Under Curve (AUC) for ROC\n",
    "ROC curve:\n",
    "An ROC curve (receiver operating characteristic curve) is a graph showing the performance of a classification model at all classification thresholds. This curve plots two parameters:\n",
    "\n",
    "True Positive Rate\n",
    "False Positive Rate\n",
    "True Positive Rate (TPR) is a synonym for recall and is therefore defined as follows:\n",
    "\n",
    "False Positive Rate (FPR) is defined as follows:\n",
    "\n",
    "An ROC curve plots TPR vs. FPR at different classification thresholds. Lowering the classification threshold classifies more items as positive, thus increasing both False Positives and True Positives. The following figure shows a typical ROC curve\n",
    "\n",
    "    AUC ranges in value from 0 to 1. A model whose predictions are 100% wrong has an AUC of 0.0; one whose predictions are 100% correct has an AUC of 1.0.\n",
    "\n",
    "AUC is desirable for the following two reasons:\n",
    "\n",
    "AUC is scale-invariant. It measures how well predictions are ranked, rather than their absolute values.\n",
    "AUC is classification-threshold-invariant. It measures the quality of the model's predictions irrespective of what classification threshold is chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Complexity of the model\n",
    "Finally check the complexity of the model, does it really needs to be complex?\n",
    "\n",
    "Calculate the size of a model, use regularization\n",
    "Ridge Regression or Lasso\n",
    "\n",
    "One way to reduce model complexity is to use a regularization function that encourages weights to be exactly zero. For linear models such as regression, a zero weight is equivalent to not using the corresponding feature at all. In addition to avoiding overfitting, the resulting model will be more efficient.\n",
    "\n",
    "To calculate the model size, we simply count the number of parameters that are non-zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
